import numpy as np 
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import MinMaxScaler
from sklearn.ensemble import RandomForestClassifier

#cargar la data con x e y de los balanceados que son los dos arreglos que contiene
X = np.load('desbalanceados.npz')['X']
Y = np.load('desbalanceados.npz')['Y']

#imprimir cantidad del arreglo
print(X.shape)
print(Y)

#partición 60 train 40 rest
x_train, x_rest, y_train, y_rest = train_test_split(X, Y, test_size=0.4, random_state=20, stratify=Y,)
#partición rest en 2 mitades
x_val, x_test, y_val, y_test = train_test_split(x_rest, y_rest, test_size=0.5, random_state=321, stratify= y_rest,)

#Verificación 
print('Tamaños:')
print('\tDataset original:', X.shape, Y.shape)
print('\tEntrenamiento:', x_train.shape, y_train.shape)
print('\tValidación:', x_val.shape, y_val.shape)
print('\tPrueba:', x_test.shape, y_test.shape)

print('Proporciones categorías (0s/1s):')
print(f'\tDataset original:{np.sum(Y==0)/len(Y)}/{np.sum(Y==1)/len(Y)}')
print(f'\tEntrenamiento:{np.sum(y_train==0)/len(y_train)}/{np.sum(y_train==1)/len(y_train)}')
print(f'\tValidación:{np.sum(y_val==0)/len(y_val)}/{np.sum(y_val==1)/len(y_val)}')
print(f'\tPrueba:{np.sum(y_test==0)/len(y_test)}/{np.sum(y_test==1)/len(y_test)}')

#valores minimos y máximos
print(f'x_train: {x_train.min(axis=0)}/{x_train.max(axis=0)}')
print(f'x_val: {x_val.min(axis=0)}/{x_val.max(axis=0)}')
print(f'x_train: {x_test.min(axis=0)}/{x_test.max(axis=0)}')

scaler = MinMaxScaler(feature_range=(-1,1))

#fit_transform() sobre el set de entrenamiento
x_train_s = scaler.fit_transform(x_train)  

#Mostramos los mínimos y los máximos calculados por el escalador
print(f'Mínimos de "x_train": {x_train.min(axis=0)}')
print(f'Mínimos calculados por el escalador: {scaler.data_min_}') 
print('-'*50)
print(f'Máximos de "x_train": {x_train.max(axis=0)}')
print(f'Máximos calculados por el escalador: {scaler.data_max_}')

#Verificamos que x_train_s contiene ahora los datos escalados al rango de -1 y 1
print(f'x_train_s: {x_train_s.min(axis=0)}/{x_train_s.max(axis=0)}') 

#Usamos scaler con el método transform para transformar los sets de validación y prueba, y verificamos los rangos
x_val_s = scaler.transform(x_val)
x_test_s = scaler.transform(x_test)
print(f'x_val_s:{x_val_s.min(axis=0)}/{x_val_s.max(axis=0)}')
print(f'x_test_s:{x_test_s.min(axis=0)}/{x_test_s.max(axis=0)}')

#Crear instancia del estimador(modelo)
bosque = RandomForestClassifier()

#Entrenamiento del modelo
bosque.fit(x_train, y_train)

#Validar el modelo, es decir comparar el desempeño con los sets de entrenamiento y validación, para determinar si hay overfitting o underfitting
print(f'Exactitud promedio entrenamiento: {bosque.score(x_train,y_train)}')
print(f'Exactitud promedio validación: {bosque.score(x_val,y_val)}')

print(f'Exactitud promedio prueba: {bosque.score(x_test,y_test)}')

#Suponiendo que estamos conformes con los resultados, lo que falaría sería generar predicciones, aunque en este caso no estariamos conformes
#porque faltan datos para el entrenamiento y a salido una puntuación en validacion de 0,5 y en entrenamiento un 1
y_pred = bosque.predict(x_test)
print('Categorías reales:', y_test)
print('Categorías predichas:', y_pred) 

#Hacemos un ejemplo de clasificacion con las siguientes caracteristicas
datoapredecir = np.array([[1.0002,2.3,3.4]])
prediccion = bosque.predict(datoapredecir)
print('Prediccion del numero 3:', prediccion[0])